# ğŸ“˜ Splunk Core Certified Power User Notes

> Professionally organized notes for SPLK-1002 exam preparation.

---

<details>
<summary>ğŸ“˜ 1. Introduction to Splunk</summary>

```
==============================
1. Introduction to Splunk
==============================

What is Splunk?
---------------
Splunk is a powerful platform for searching, monitoring, and analyzing machine-generated big data via a web-style interface. It stores, indexes, and correlates real-time data in a searchable repository from which it can generate graphs, reports, alerts, dashboards, and visualizations.

Why Use Splunk?
---------------
- Centralized log analysis
- Real-time monitoring
- Powerful dashboards
- Alerting and automation
- Extensible via apps and add-ons

Splunk Components:
------------------
1. **Universal Forwarder (UF)** â€“ Lightweight agent that sends logs to Splunk Indexer.
2. **Indexer** â€“ Parses and indexes the incoming data.
3. **Search Head (SH)** â€“ Frontend used to run searches and build visualizations.
4. **Deployment Server** â€“ Manages configurations for multiple Splunk instances.

Data Flow in Splunk:
--------------------
1. Log sources â†’ UF â†’ Indexer â†’ SH
2. Raw data â†’ Parsing â†’ Indexing â†’ Searching â†’ Reporting

Indexes:
--------
- Logical data storage locations (like folders)
- Default index: `main`
- Custom indexes can be created

Example Log (from secure.log):
------------------------------
`Jun 08 18:20:24 sshd[4747]: Failed password for invalid user john from 10.0.0.4 port 22`

Basic Search:
-------------
```splunk
index=linux_logs sourcetype=secure.log "Failed password"
```

Exam Tips:
----------
ğŸ“Œ Understand each Splunk component and its role.
ğŸ“Œ Know the data flow and difference between UF, Indexer, and SH.
ğŸ“Œ Remember where parsing, indexing, and searching occur.

</details>

<details>
<summary>ğŸ“˜ 2. Navigating the Splunk Interface</summary>

```
==============================
2. Navigating the Splunk Interface
==============================

Overview:
---------
Splunk's Web Interface (Search Head) is where analysts perform searches, build dashboards, create alerts, and view visualizations.

Main UI Components:
-------------------
1. Search Bar â€“ Where SPL queries are written.
2. Time Range Picker â€“ Choose time windows like "Last 24 hours" or custom time.
3. Sidebar Panel â€“ Displays Datasets, Reports, Alerts, Apps, and Settings.
4. Fields Panel â€“ Shows all indexed and extracted fields for each event.
5. Events Viewer â€“ Displays event logs with field highlighting.

Time Range Picker:
------------------
This is critical to scope your searches correctly.

Search Modes:
-------------
1. Fast â€“ Fastest, skips field discovery.
2. Smart â€“ Default mode, balances speed and field discovery.
3. Verbose â€“ Slower, discovers all fields.

Field Discovery:
----------------
Selected Fields: _time, host, source, sourcetype
Interesting Fields: Splunk's suggested fields

Example:
--------
```splunk
index=linux_logs sourcetype=secure.log "Failed password"
| stats count by user
```

Exam Tips:
----------
ğŸ“Œ Know what each UI panel is used for.
ğŸ“Œ Understand when to use Fast vs. Smart vs. Verbose search modes.
ğŸ“Œ The Time Picker greatly affects results â€” avoid forgetting to check it!

</details>


<details>
<summary>ğŸ“˜ 3. Time Ranges in Splunk</summary>

```
==============================
3. Time Ranges in Splunk
==============================

Overview:
---------
Time range selection is one of the most critical aspects of Splunk searches.

Time Picker Presets:
--------------------
- Last 15 minutes
- Last 24 hours
- Last 7 days
- Yesterday
- Real-time

Relative Time:
--------------
- `-1h@h` = 1 hour ago aligned to hour
- `-15m@m` = 15 minutes ago, aligned to minute

Time Modifiers in SPL:
----------------------
```splunk
index=syslog earliest=-2h
index=syslog earliest="07/27/2025:08:00:00" latest="07/27/2025:10:00:00"
```

Real-Time Searches:
-------------------
- Live dashboarding
- Use with care (high system usage)

Example Query:
--------------
```splunk
index=linux_logs sourcetype=secure.log "Failed password"
| stats count by src_ip
| where count > 10
earliest=-1h
```

Exam Tips:
----------
ğŸ“Œ Set the right time range before running queries.
ğŸ“Œ Know real-time vs. historical tradeoffs.
ğŸ“Œ Understand time modifiers (`earliest`, `latest`).

</details>


<details>
<summary>ğŸ“˜ 4. SPL Syntax and Search Pipeline</summary>

```
==============================
4. SPL Syntax and Search Pipeline
==============================

Overview:
---------
SPL (Search Processing Language) is how you query data in Splunk.

Structure:
----------
Each command is separated by a pipe (`|`) symbol.

Example:
--------
```splunk
index=web sourcetype=access_combined
| stats count by status
```

Command Types:
--------------
- Search: `index=main`
- Transforming: `stats`, `chart`, `timechart`
- Filtering: `where`, `fields`, `dedup`
- Eval: `eval`, `if`, `case`
- Format: `table`, `sort`

Example Query:
--------------
```splunk
index=web sourcetype=access_combined
| eval is_error=if(status>=400, "yes", "no")
| stats count by is_error
```

Real-World Example:
-------------------
```splunk
index=linux_logs sourcetype=secure.log "Failed password"
| eval day=strftime(_time, "%A")
| stats count by day, user
```

Exam Tips:
----------
ğŸ“Œ SPL syntax is case-sensitive.
ğŸ“Œ Donâ€™t forget the `|` between commands.
ğŸ“Œ Understand the role of each command type in the pipeline.

</details>


<details>
<summary> ğŸ“˜ 5. Using Fields and Field Extraction</summary>

```
==============================
5. Using Fields and Field Extraction
==============================

Overview:
---------
Fields are key-value pairs extracted from event data. Splunk automatically extracts some fields and allows manual extractions.

Types of Fields:
----------------
- Default Fields: _time, host, source, sourcetype
- Indexed Fields: Extracted at index time (e.g., host)
- Search-time Fields: Extracted when a search is run (e.g., status)

Field Panels:
-------------
- Selected Fields: Always shown in UI
- Interesting Fields: Frequently occurring in current results

Field Extraction Methods:
-------------------------
1. Interactive Extraction â€“ via UI (Settings > Fields > Field Extractions)
2. Using `rex` â€“ Regular expression based extraction
3. Using `spath` â€“ Extract fields from JSON logs

Example using `rex`:
---------------------
index=linux_logs sourcetype=secure.log
| rex "Failed password for (?<user>\w+) from (?<ip>\d+\.\d+\.\d+\.\d+)"

Example using `spath` (for JSON):
---------------------------------
index=api sourcetype=json_logs
| spath input=payload path=user.id output=user_id

Best Practices:
---------------
- Use `rex` for unstructured logs
- Use `spath` for JSON or XML
- Avoid extracting the same field multiple times

Exam Tips:
----------
ğŸ“Œ Understand difference between indexed vs search-time fields.
ğŸ“Œ Practice both `rex` and `spath` syntax.
ğŸ“Œ Know where to configure field extractions in the UI.
```
</details>


<details>
<summary>ğŸ“˜ 6. Using Search Modes</summary>

```
==============================
6. Using Search Modes
==============================

Overview:
---------
Search Modes determine how much field discovery Splunk performs, which affects speed and detail.

Modes:
------
1. Fast â€“ Minimal field extraction; fastest.
2. Smart â€“ Balanced; default mode.
3. Verbose â€“ Maximum field extraction; slowest.

When to Use:
------------
- Fast: For saved reports, known fields
- Smart: General searching
- Verbose: Exploratory searching

Comparison Table:
-----------------
Mode     | Field Discovery | Speed
---------|------------------|-------
Fast     | Minimal          | ğŸ”¥ Fast
Smart    | Conditional      | âš–ï¸ Balanced
Verbose  | Full             | ğŸ¢ Slow

Exam Tips:
----------
ğŸ“Œ Know when to switch modes.
ğŸ“Œ Verbose is needed for field discovery.
ğŸ“Œ Smart adjusts based on pipeline usage.
```
</details>


<details>
<summary>ğŸ“˜ 7. Transforming Commands</summary>

```
==============================
7. Transforming Commands
==============================

Overview:
---------
Transforming commands are used to calculate statistics and create charts or time-based trends.

Common Commands:
----------------
1. stats â€“ Aggregates data
2. chart â€“ Like stats but output in table format
3. timechart â€“ Time-based trends

Examples:
---------
index=web sourcetype=access_combined
| stats count by status

index=web sourcetype=access_combined
| chart avg(bytes) over status by host

index=web
| timechart span=1h count by status

Transforming Functions:
-----------------------
- count
- avg
- sum
- min
- max
- dc (distinct count)
- values (list unique)

Best Practices:
---------------
- Use timechart when _time is needed
- Use dc(field) for distinct users/IPs
- Always verify fields exist before using them

Exam Tips:
----------
ğŸ“Œ Understand difference between stats, chart, and timechart.
ğŸ“Œ Know transforming functions (avg, dc, sum, etc.).
ğŸ“Œ Timechart requires _time field.
```
</details>


<details>
<summary>ğŸ“˜ 8. Data Visualizations & Dashboards</summary>

```
==============================
8. Data Visualizations & Dashboards
==============================

Overview:
---------
Dashboards visualize search results using charts, tables, and gauges.

Common Visualization Types:
---------------------------
- Column and Bar charts
- Line and Area charts
- Pie and Scatter plots
- Single value, Gauge

Creating Dashboards:
--------------------
- Use "Save As > Dashboard Panel" after running a search.
- Combine multiple panels in one dashboard.

Modifying Panels:
-----------------
- Change chart type, title, color scheme
- Use tokens to pass values between inputs and panels

Best Practices:
---------------
- Use dropdown filters for interactivity
- Title each panel meaningfully
- Donâ€™t overload with too many panels

Exam Tips:
----------
ğŸ“Œ You can save searches as dashboard panels.
ğŸ“Œ Know the types of visualizations.
ğŸ“Œ Use dynamic filters and inputs for reusability.
```
</details>


<details>
<summary>ğŸ“˜ 9. Creating and Using Reports</summary>

```
==============================
9. Creating and Using Reports
==============================

Overview:
---------
Reports are saved searches that can be scheduled and shared.

Creating a Report:
------------------
- Run a search
- Click "Save As > Report"
- Set a title, description, permissions

Scheduling:
-----------
- You can schedule reports to run at set intervals
- Set actions like email, PDF export, alert trigger

Managing Reports:
-----------------
- Go to Settings > Searches, Reports, Alerts
- Modify permissions, owners, schedule

Difference from Dashboards:
---------------------------
Feature     | Report                  | Dashboard
------------|-------------------------|-------------------------
Purpose     | Scheduled results       | Interactive view
Output      | Table or chart          | Multiple visual panels
Scheduling  | Yes                     | No (but can refresh)

Exam Tips:
----------
ğŸ“Œ Reports are saved searches.
ğŸ“Œ You can schedule and share reports.
ğŸ“Œ Reports can send emails or trigger alerts.
```
</details>


<details>
<summary>ğŸ“˜ 10. Alerts and Scheduled Searches</summary>

```
==============================
10. Alerts and Scheduled Searches
==============================

Overview:
---------
Alerts are saved searches with conditions that notify you when triggered.

Creating an Alert:
------------------
- Run a search
- Click â€œSave As > Alertâ€
- Set trigger condition (number of results, custom logic)
- Choose actions: email, webhook, script

Alert Types:
------------
- Real-time: Triggered as soon as condition met
- Scheduled: Runs at intervals and checks for match

Trigger Conditions:
-------------------
- Per-result (trigger for each event)
- Number of results (e.g. >100 errors)

Actions:
--------
- Send email
- Webhook
- Log to index
- Run script

Best Practices:
---------------
- Avoid real-time unless truly needed
- Use summary indexing for frequent alerts
- Include enough info in alert email

Exam Tips:
----------
ğŸ“Œ Know difference between real-time vs scheduled.
ğŸ“Œ Understand how to configure trigger conditions.
ğŸ“Œ Alerts are just scheduled searches with actions.
```
</details>


<details>
<summary>ğŸ“˜ 11. Event Types and Tags</summary>

```
==============================
11. Event Types and Tags
==============================

Overview:
---------
Event types group similar events under a name, allowing easier reuse.

Creating Event Types:
---------------------
- Search for logs
- Click "Save As > Event Type"
- Provide a name and optional tag

Tags:
-----
- Labels applied to field values or event types
- Help categorize data (e.g., tag IPs as internal/external)

Example:
--------
`tag=authentication` could include event types like `login_success` and `login_failure`

Best Practices:
---------------
- Use consistent naming
- Combine tags with lookups for context

Exam Tips:
----------
ğŸ“Œ Event types are named saved searches.
ğŸ“Œ Tags help group events logically.
ğŸ“Œ Tags are useful for CIM and accelerated datasets.
```
</details>


<details>
<summary>ğŸ“˜ 12. Lookups and Field Enrichment</summary>

```
==============================
12. Lookups and Field Enrichment
==============================

Overview:
---------
Lookups enrich event data by matching fields with external CSV or KV store.

Types of Lookups:
-----------------
1. **File-based (.csv)**
2. **External (scripts)**
3. **KV Store (indexed DB)**

Common Commands:
----------------
- inputlookup â€“ view lookup contents
- lookup â€“ enrich events
- outputlookup â€“ write results

Example:
--------
index=web | lookup ip2location ip AS client_ip OUTPUT city, country

Automatic Lookups:
------------------
- Apply based on sourcetype
- Configured under Settings > Fields > Lookup Definitions

Best Practices:
---------------
- Use lookups to map codes, geo info, user info
- Keep lookup file updated

Exam Tips:
----------
ğŸ“Œ Understand inputlookup vs lookup vs outputlookup.
ğŸ“Œ Know where automatic lookups are defined.
ğŸ“Œ Know CSV formatting and matching fields.
```
</details>


<details>
<summary>ğŸ“˜ 13. Calculated Fields, Aliases, and Field Extractions</summary>

```
==============================
13. Calculated Fields, Aliases, and Field Extractions
==============================

Overview:
---------
Splunk lets you create fields dynamically to simplify searches and improve performance.

Calculated Fields:
------------------
- Use eval expressions to define new fields
- Applied at search-time

Field Aliases:
--------------
- Rename fields without changing underlying data
- Example: rename clientip to ip_address

Field Extractions:
------------------
- Use regex or delimiters to define fields
- Created via UI or props.conf

Exam Tips:
----------
ğŸ“Œ Calculated fields use eval.
ğŸ“Œ Field aliases map one field name to another.
ğŸ“Œ Field extractions = making fields from raw logs.
```
</details>


<details>
<summary>ğŸ“˜ 14. Splunk Knowledge Objects Summary</summary>

```
==============================
14. Splunk Knowledge Objects Summary
==============================

Overview:
---------
Knowledge Objects are reusable components that enhance Splunk functionality.

Key Objects:
------------
- Event Types
- Tags
- Lookups
- Reports
- Alerts
- Dashboards
- Data Models
- Field Extractions
- Saved Searches

Management:
-----------
- Settings > Knowledge
- Permissions control sharing (Private, App, Global)

Best Practices:
---------------
- Use naming conventions
- Tag and organize for reuse

Exam Tips:
----------
ğŸ“Œ Know which object is used where.
ğŸ“Œ Permissions and ownership impact usage.
ğŸ“Œ All objects are found in Settings > Knowledge.
```
</details>

---

<details>
<summary>ğŸ“˜ 15. Combined Exam Tips (All Sections)</summary>

```
==============================
15. Combined Exam Tips (All Sections)
==============================

This section consolidates the most important exam tips scattered across all prior sections and lecture screenshots.

General Exam Tips:
------------------
âœ… Understand the architecture â€“ role of Indexer, Search Head, Universal Forwarder  
âœ… Know the difference between real-time, scheduled, and historical searches  
âœ… Use Time Picker wisely â€“ avoid querying too much data  
âœ… SPL is case-sensitive â€“ especially field names  
âœ… Syntax errors often stem from missing `|` or incorrect field references  
âœ… Save time by knowing when to use Fast, Smart, or Verbose search modes  
âœ… Pay attention to default vs. interesting fields in the Fields panel  
âœ… Practice regex (`rex`) and JSON field extraction (`spath`)  
âœ… Use `eval` to create dynamic fields and `stats` for summary views  
âœ… `timechart` always needs `_time` field  
âœ… Reports vs Dashboards: Reports are for static outputs, Dashboards are for interactive visualization  
âœ… Alerts are scheduled searches with trigger conditions and actions  
âœ… Lookup usage is critical â€“ understand `inputlookup`, `lookup`, and `outputlookup`  
âœ… Knowledge objects and their permissions (private, app, global) frequently appear in exams  

Pro Tips from Lecture:
----------------------
âœ… Pivot allows visualization without writing SPL â€“ good for business users  
âœ… Accelerated Datasets enhance dashboard speed â€“ ideal for scheduled panels  
âœ… Use calculated fields instead of rewriting SPL every time  
âœ… Donâ€™t mix index-time and search-time field logic in same query  
âœ… Tags and event types are critical for data model mapping and CIM compliance  
âœ… Real-time alerts are costly â€“ prefer scheduled unless justified  
âœ… Field aliasing is useful when dealing with multiple sourcetypes  
âœ… Use summary indexing to reduce computation for frequent reports/alerts  
âœ… Use dropdowns and dynamic filters in dashboards to enhance usability  
âœ… Use `dc()` for distinct count and `values()` to list unique items

Suggested Strategy for Exam:
----------------------------
ğŸ§  Memorize SPL syntax and functions: `stats`, `eval`, `dedup`, `chart`, `table`, `sort`, `rename`  
ğŸ§ª Practice queries using provided sample logs (e.g., `secure.log`)  
ğŸ§© Use scenario-based logic: Know what search should be used to troubleshoot login issues or network errors  
ğŸ“Š Practice building dashboards from raw searches  
ğŸ—‚ï¸ Understand the difference between fields, tags, event types, and calculated fields  

Recommended Practice:
---------------------
- Write at least 50 SPL queries using transforming + filtering commands  
- Create a dashboard with at least 3 panels: timechart, bar, and single-value  
- Configure a scheduled alert with condition >10 failed login attempts in 1h  
- Perform a lookup join with external CSV data  
- Use `rex` to extract usernames from secure.log manually
```
</details>

âœ… **Prepared for certification + real-world analyst usage**  
ğŸ“ Includes: Search commands, Dashboards, Alerts, Knowledge objects  
